{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc022d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/matx/u/bmc0407/conda/weaver/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f162d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['original_instruction', 'problem', 'level', 'type', 'options', 'solution', 'correct_answer', 'options_original_order', 'answer', 'subject', 'instruction', 'samples', 'extracted_answers', 'answer_correct', 'GRM_scores', 'Skyworks_scores', 'URM_scores', 'QRM_scores', 'GPM_scores', 'GRMLlama32_scores', 'OffsetBias_scores', 'GRMGemma_scores', 'ArmorRM_scores', 'QwenPRM_min_scores', 'QwenPRM_max_scores', 'QwenPRM_avg_scores', 'EurusPRMStage1_min_scores', 'EurusPRMStage1_max_scores', 'EurusPRMStage1_avg_scores', 'EurusPRMStage2_min_scores', 'EurusPRMStage2_max_scores', 'EurusPRMStage2_avg_scores', 'InternLM2Reward7B_scores', 'weaver_scores'],\n",
       "    num_rows: 646\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_from_disk(\"selection/hazyresearch/GPQA_with_Llama_3.1_8B_Instruct_v1\")[\"data\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfeee0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04451998103998908\n"
     ]
    }
   ],
   "source": [
    "# so we have a score for each candidate generation from weaver\n",
    "# so this is what we want to sum to 1 since we're choosign between generations\n",
    "print(sum(data[\"weaver_scores\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfad17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629 2.5606056393188394\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "scores = [*scores for scores in data[\"weaver_scores\"]]\n",
    "max_idx = np.argmax(sums)\n",
    "max_sum = sums[max_idx]\n",
    "\n",
    "print(max_idx, max_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4ad4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Username: jonsaadfalcon\n",
      "Organizations: [{'type': 'org', 'id': '62c44cf7f674ac1d4da34b13', 'name': 'PrimeQA', 'fullname': 'PrimeQA', 'email': 'primeqa@ibm.com', 'canPay': False, 'periodEnd': None, 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1666580831042-6241d441a4682fb11361e5d0.jpeg', 'roleInOrg': 'write', 'isEnterprise': False}, {'type': 'org', 'id': '6428b82beb320ead3d2d6573', 'name': 'hazyresearch', 'fullname': 'HazyResearch', 'email': None, 'canPay': False, 'periodEnd': None, 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/6337537b267cee4d068f604d/L39anFZsbOCVVSkESTUqZ.png', 'roleInOrg': 'admin', 'isEnterprise': False}, {'type': 'org', 'id': '632b803bb2dd35f135623cc2', 'name': 'togethercomputer', 'fullname': 'Together', 'email': 'tech-ops+huggingface@together.xyz', 'canPay': True, 'periodEnd': 1751327999, 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1678734258201-6322ad266b1992383fa964ca.png', 'roleInOrg': 'write', 'isEnterprise': True, 'resourceGroups': []}, {'type': 'org', 'id': '64fb7314010f41e43533cd3f', 'name': 'ContextualAI', 'fullname': 'ContextualAI', 'email': 'payables@contextual.ai', 'canPay': True, 'periodEnd': 1751327999, 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/5f07383b19cb630495b812cd/X73iQ9Sp9Ip_IRudogaKg.png', 'roleInOrg': 'write', 'isEnterprise': False}, {'type': 'org', 'id': '66ae7454ba986cbec5e40618', 'name': 'ScalingIntelligence', 'fullname': 'Scaling Intelligence', 'email': None, 'canPay': False, 'periodEnd': None, 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/60799bed489fc71534e91bf3/4lE95REjtvr10X0H4URqK.png', 'roleInOrg': 'admin', 'isEnterprise': False}]\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import whoami\n",
    "\n",
    "# Check current user\n",
    "user_info = whoami()\n",
    "print(f\"Username: {user_info['name']}\")\n",
    "print(f\"Organizations: {user_info.get('orgs', [])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997dd38c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ab5203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac852f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating data split: 100%|██████████| 500/500 [00:01<00:00, 274.25 examples/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 16] Device or resource busy: '.nfs000000000005f66500004fb3'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m data = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhazyresearch/MMLU-Pro_with_Llama_3.1_8B_Instruct_v1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m data[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mweaver_scores\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m2\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/matx/u/bmc0407/conda/weaver/lib/python3.11/site-packages/datasets/load.py:2084\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[39m\n\u001b[32m   2081\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance.as_streaming_dataset(split=split)\n\u001b[32m   2083\u001b[39m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2084\u001b[39m \u001b[43mbuilder_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2085\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2086\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2087\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2088\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2089\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2090\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2092\u001b[39m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[32m   2093\u001b[39m keep_in_memory = (\n\u001b[32m   2094\u001b[39m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance.info.dataset_size)\n\u001b[32m   2095\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/matx/u/bmc0407/conda/weaver/lib/python3.11/site-packages/datasets/builder.py:916\u001b[39m, in \u001b[36mDatasetBuilder.download_and_prepare\u001b[39m\u001b[34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28mself\u001b[39m._check_manual_download(dl_manager)\n\u001b[32m    915\u001b[39m \u001b[38;5;66;03m# Create a tmp dir and rename to self._output_dir on successful exit.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mincomplete_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_output_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtmp_output_dir\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Temporarily assign _output_dir to tmp_data_dir to avoid having to forward\u001b[39;49;00m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# it to every sub function.\u001b[39;49;00m\n\u001b[32m    919\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtemporary_assignment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_output_dir\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_output_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_format\u001b[49m\u001b[43m}\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/matx/u/bmc0407/conda/weaver/lib/python3.11/contextlib.py:144\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.gen)\n\u001b[32m    145\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    146\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/matx/u/bmc0407/conda/weaver/lib/python3.11/site-packages/datasets/builder.py:892\u001b[39m, in \u001b[36mDatasetBuilder.download_and_prepare.<locals>.incomplete_dir\u001b[39m\u001b[34m(dirname)\u001b[39m\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m tmp_dir\n\u001b[32m    891\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.isdir(dirname):\n\u001b[32m--> \u001b[39m\u001b[32m892\u001b[39m     \u001b[43mshutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[38;5;66;03m# LocalFileSystem.mv does copy + rm, it is more efficient to simply rename a local directory\u001b[39;00m\n\u001b[32m    894\u001b[39m shutil.move(tmp_dir, dirname)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/matx/u/bmc0407/conda/weaver/lib/python3.11/shutil.py:752\u001b[39m, in \u001b[36mrmtree\u001b[39m\u001b[34m(path, ignore_errors, onerror, dir_fd)\u001b[39m\n\u001b[32m    750\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    751\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.samestat(orig_st, os.fstat(fd)):\n\u001b[32m--> \u001b[39m\u001b[32m752\u001b[39m         \u001b[43m_rmtree_safe_fd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    753\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    754\u001b[39m             os.close(fd)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/matx/u/bmc0407/conda/weaver/lib/python3.11/shutil.py:703\u001b[39m, in \u001b[36m_rmtree_safe_fd\u001b[39m\u001b[34m(topfd, path, onerror)\u001b[39m\n\u001b[32m    701\u001b[39m     os.unlink(entry.name, dir_fd=topfd)\n\u001b[32m    702\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m     \u001b[43monerror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43munlink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/matx/u/bmc0407/conda/weaver/lib/python3.11/shutil.py:701\u001b[39m, in \u001b[36m_rmtree_safe_fd\u001b[39m\u001b[34m(topfd, path, onerror)\u001b[39m\n\u001b[32m    699\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    700\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m         os.unlink(entry.name, dir_fd=topfd)\n\u001b[32m    702\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m    703\u001b[39m         onerror(os.unlink, fullname, sys.exc_info())\n",
      "\u001b[31mOSError\u001b[39m: [Errno 16] Device or resource busy: '.nfs000000000005f66500004fb3'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset(\"hazyresearch/MMLU-Pro_with_Llama_3.1_8B_Instruct_v1\")\n",
    "data[\"data\"][\"weaver_scores\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5386c306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/matx/u/bmc0407/conda/weaver/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "DatasetNotFoundError",
     "evalue": "Dataset 'GPQA_Diamond_with_Llama_3.1_70B_Instruct_up_to_1K_Samples_v1' doesn't exist on the Hub or cannot be accessed.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mDatasetNotFoundError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m data = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGPQA_Diamond_with_Llama_3.1_70B_Instruct_up_to_1K_Samples_v1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/matx/u/bmc0407/conda/weaver/lib/python3.11/site-packages/datasets/load.py:2062\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[39m\n\u001b[32m   2057\u001b[39m verification_mode = VerificationMode(\n\u001b[32m   2058\u001b[39m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode.BASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode.ALL_CHECKS\n\u001b[32m   2059\u001b[39m )\n\u001b[32m   2061\u001b[39m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2062\u001b[39m builder_instance = \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2063\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2064\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2065\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2066\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2067\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2068\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2075\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   2076\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2077\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2079\u001b[39m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[32m   2080\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/matx/u/bmc0407/conda/weaver/lib/python3.11/site-packages/datasets/load.py:1782\u001b[39m, in \u001b[36mload_dataset_builder\u001b[39m\u001b[34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[39m\n\u001b[32m   1780\u001b[39m     download_config = download_config.copy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[32m   1781\u001b[39m     download_config.storage_options.update(storage_options)\n\u001b[32m-> \u001b[39m\u001b[32m1782\u001b[39m dataset_module = \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1783\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1784\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1785\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1786\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1787\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1790\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1791\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1792\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[32m   1795\u001b[39m builder_kwargs = dataset_module.builder_kwargs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/matx/u/bmc0407/conda/weaver/lib/python3.11/site-packages/datasets/load.py:1652\u001b[39m, in \u001b[36mdataset_module_factory\u001b[39m\u001b[34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[39m\n\u001b[32m   1650\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt reach the Hugging Face Hub for dataset \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1651\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, (DataFilesNotFoundError, DatasetNotFoundError, EmptyDatasetError)):\n\u001b[32m-> \u001b[39m\u001b[32m1652\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1653\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m):\n\u001b[32m   1654\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trust_remote_code:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/matx/u/bmc0407/conda/weaver/lib/python3.11/site-packages/datasets/load.py:1578\u001b[39m, in \u001b[36mdataset_module_factory\u001b[39m\u001b[34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[39m\n\u001b[32m   1574\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(\n\u001b[32m   1575\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRevision \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt exist for dataset \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m on the Hub.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1576\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1577\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1578\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt exist on the Hub or cannot be accessed.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1579\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1580\u001b[39m     dataset_script_path = api.hf_hub_download(\n\u001b[32m   1581\u001b[39m         repo_id=path,\n\u001b[32m   1582\u001b[39m         filename=filename,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1585\u001b[39m         proxies=download_config.proxies,\n\u001b[32m   1586\u001b[39m     )\n",
      "\u001b[31mDatasetNotFoundError\u001b[39m: Dataset 'GPQA_Diamond_with_Llama_3.1_70B_Instruct_up_to_1K_Samples_v1' doesn't exist on the Hub or cannot be accessed."
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset(\"hazyresearch/GPQA_Diamond_with_Llama_3.1_70B_Instruct_up_to_1K_Samples_v1\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2cc678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weaver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
